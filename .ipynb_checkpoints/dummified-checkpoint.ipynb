{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/Kenneth S. Hansen/Dropbox/NYC Data Science/Projects/Kaggle/test.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7b9eef730947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/Kenneth S. Hansen/Dropbox/NYC Data Science/Projects/Kaggle/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/Kenneth S. Hansen/Dropbox/NYC Data Science/Projects/Kaggle/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/Kenneth S. Hansen/Dropbox/NYC Data Science/Projects/Kaggle/test.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('/Users/Kenneth S. Hansen/Dropbox/NYC Data Science/Projects/Kaggle/test.csv')\n",
    "df_train = pd.read_csv('/Users/Kenneth S. Hansen/Dropbox/NYC Data Science/Projects/Kaggle/train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response variable - SalePrice\n",
    "- Rigth / positive skewness\n",
    "- The response variable is NOT normal distributed, which means that we're violating our assumption in respect no normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train['SalePrice'].describe())\n",
    "#Histogram\n",
    "import seaborn as sns\n",
    "print(sns.distplot(df_train['SalePrice']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking how much SalePrice deviate from a normal distribution\n",
    "- Since it's very likely that I'm going to perform regressions (linear models), my depedent variables need to be \"somewhat\" normal distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = stats.probplot(df_train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Response Variable - SalePrice\n",
    "- Log Transform SalePrice\n",
    "- Reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['SalePrice'] = np.log(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the transformed response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df_train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "- Merging train and validate\n",
    "- Impute missing values (Handling missing data)\n",
    "- Categorical versus Numeric\n",
    "\n",
    "- df.all.describe(): shows a summary of the numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obs remember to exclude response variable, SalePrice\n",
    "frames = [df_train, df_test]\n",
    "df_all = pd.concat(frames)\n",
    "\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values - Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=0, summing each row for each column\n",
    "#isnull = return an boolean depending on missing or not\n",
    "\n",
    "#Calculat the ratio of missing values\n",
    "missing = (df_all.isnull().sum(axis=0) / len(df_all)*100).sort_values(ascending=False)\n",
    "\n",
    "#Dropping all \n",
    "missing = missing.drop(missing[missing==0].index)\n",
    "\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing})\n",
    "missing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated missing value table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=0, summing each row for each column\n",
    "#isnull = return an boolean depending on missing or not\n",
    "\n",
    "#Calculat the ratio of missing values\n",
    "missing1 = (df_all.isnull().sum(axis=0) / len(df_all)*100).sort_values(ascending=False)\n",
    "\n",
    "#Dropping all \n",
    "missing1 = missing1.drop(missing1[missing1==0].index)\n",
    "\n",
    "missing_data_updated = pd.DataFrame({'Missing Ratio' :missing1})\n",
    "missing_data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=missing.index, y=missing)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Percent of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting variables that are more than 50% missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.drop(['Utilities', 'PoolArea', 'MiscFeature', 'FireplaceQu', 'Fence', 'Alley'], axis=1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoolQC\n",
    "- I perceive these features as being \"somewhat\" important, and these can indeed help explain the variation in my predictor SalePrice. The risk of converting these four variables into 1 and 0 is that I lose potential infromation in the levels.\n",
    "- Consider to go back and keep the levels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NA with None\n",
    "List_ = ['PoolQC']\n",
    "df_all[List_] = df_all[List_].fillna('None')\n",
    "\n",
    "#Function to convert none = 0, and all other categories = 1\n",
    "def replace(x):\n",
    "    if x == 'None':\n",
    "        return 0\n",
    "    if x != 'None':\n",
    "        return 1\n",
    "   \n",
    " \n",
    "df_all['PoolQC'] = df_all['PoolQC'].apply(replace)\n",
    "\n",
    "print(df_all['PoolQC'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CentralAir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.Series(df_all['CentralAir'].replace('Y', 1).replace('[^Y]', 0, regex=True))\n",
    "df_all['CentralAir'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['CentralAir'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3SsnPorch, LowQualFinSF \n",
    "- Convert into binary. Either the property has a house or it hasn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_ = ['3SsnPorch', 'LowQualFinSF']\n",
    "def replace1(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    if x != 0:\n",
    "        return 1\n",
    "\n",
    "df_all['3SsnPorch'] = df_all['3SsnPorch'].apply(replace1)\n",
    "df_all['LowQualFinSF'] = df_all['LowQualFinSF'].apply(replace1)\n",
    "print(df_all['3SsnPorch'].value_counts())\n",
    "print(df_all['LowQualFinSF'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotFrontage\n",
    "- LotFrontage is skweded, which means that we need to transform the variable. Here, there is a lot of various options. In this case, I take the median due the fact that we have extremes values. Taking the median makes the distribution less sensitive to these extremes values compared with taking the mean for instance.\n",
    "- Number of missing values: 486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing missing values - LotFrontage\n",
    "- Sqrt of area as imputing, we assume that the lot is \"close\" to be sqaure shaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all.LotFrontage.isnull(), 'LotFrontage'] = np.sqrt(df_all.loc[df_all.LotFrontage.isnull()].LotArea)\n",
    "print(df_all['LotFrontage'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['LotFrontage'].describe())\n",
    "#Histogram\n",
    "import seaborn as sns\n",
    "sns.distplot(df_all['LotFrontage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is LotFrontage Versus SalePrice looking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'LotFrontage', y = 'SalePrice', data = df_train)\n",
    "plt.xlabel('LotFrontage')\n",
    "plt.ylabel('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garage Quality, Garage Type, Garage Finish, Garage Cond\n",
    "- Only five procent missing, and I consider to drop since GarageCars and GarageArea probably are better indicators\n",
    "- Therefore, I replace NA with None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Garage = ['GarageType', 'GarageFinish', 'GarageCond', 'GarageQual']\n",
    "df_all[List_Garage].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'GarageType', y = 'SalePrice', data = df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rplace missing values with None for Garage Quality, Garage Type, Garage Finish & Garage Condition\n",
    "df_all[List_Garage] = df_all[List_Garage].fillna('None')\n",
    "\n",
    "#confirm that 159 missing values were substitued with None\n",
    "df_all[List_Garage].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## dubble checking, what NA was replace with None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['GarageQual'] = df_all['GarageQual'].fillna('None')\n",
    "#confirm that 159 missing values were substitued with None\n",
    "df_all['GarageQual'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GarageYrBlt, Garage Area, Garage Cars\n",
    "- Replace missing with 0.\n",
    "- Seems like it is the same observations that are missing\n",
    "- GarageQuality and GarageYrBlt, this is probably due to the fact that the variable GarageCars = 0 means no cars in such garage, and therefore GarageYrBlt and GarageQuality is not represented!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Garage1 = ['GarageYrBlt', 'GarageArea', 'GarageCars']\n",
    "df_all[List_Garage1].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[List_Garage1] = df_all[List_Garage1].fillna(0)\n",
    "#confirm that NA was replaced with zero\n",
    "df_all[List_Garage1].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new variable GarageMissing, indicating that the property do NOT have a house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.Series(df_all['GarageQual'].replace('None', 1).replace('[^None]', 0, regex=True))\n",
    "df_all['GarageMissing'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath\n",
    "- All numeric values \n",
    "- Missing values means no basement\n",
    "- replace with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Bsmt_numeric = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "df_all[List_Bsmt_numeric].isnull().sum()\n",
    "#Observe that we only have few missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NA with zero\n",
    "df_all[List_Bsmt_numeric] = df_all[List_Bsmt_numeric].fillna(0)\n",
    "#confirm\n",
    "df_all[List_Bsmt_numeric].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2\n",
    "- Categorical variables\n",
    "- NA means that there is NO basement\n",
    "- Therefore replace NA with None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of missing values for each category\n",
    "List_Bsmt_categorical = ['BsmtQual', 'BsmtCond', 'BsmtExposure','BsmtFinType1', 'BsmtFinType2']\n",
    "df_all[List_Bsmt_categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing missing values\n",
    "df_all[List_Bsmt_categorical] = df_all[List_Bsmt_categorical].fillna('None')\n",
    "#Confrim that NA was replaced\n",
    "df_all[List_Bsmt_categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new variable BasementMissing, indicating that the property do NOT have an Basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.Series(df_all['BsmtQual'].replace('None', 1).replace('[^None]', 0, regex=True))\n",
    "df_all['BasementMissing'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['BasementMissing'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MasVnrArea\n",
    "- Numeric variable\n",
    "- 0 indicate no sqaure meters of \"murværk\". Since MasVnrType Na means that the house has no \"murværk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of missing\n",
    "df_all['MasVnrArea'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MasVnrArea'] = df_all['MasVnrArea'].fillna(0)\n",
    "#confirm that Na was replaced with 0\n",
    "df_all['MasVnrArea'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MasVnrType\n",
    "- Categorical variable where NA means no \"murværk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MasVnrType'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MasVnrType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MasVnrType'] = df_all['MasVnrType'].fillna(\"None\") \n",
    "#confirm that Na was replaced with 0\n",
    "df_all['MasVnrType'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSZoning\n",
    "- Only four missing observations.\n",
    "- Observe that RL is significantly more represented that the 3 other MSZonings\n",
    "- mode should be appropriate in this case. Mode replaces missing with the value that is represented most\n",
    "- Recall that 0 is rowwise, while 1 is column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all['MSZoning'].value_counts()\n",
    "(X)/(X).sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['MSZoning'].value_counts())\n",
    "print(df_all['MSZoning'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MSZoning'] = df_all['MSZoning'].fillna(df_all['MSZoning'].mode()[0])\n",
    "#Confirm that the replacement occured succesfully.\n",
    "print(df_all['MSZoning'].value_counts())\n",
    "print(df_all['MSZoning'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional\n",
    "- Categorical variable with 8 cateogories\n",
    "- describtion: : Home functionality (Assume typical unless deductions are warranted)\n",
    "- Taking the same approach as for MSzoning, type is clearly most represented!\n",
    "- Mode replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['Functional'].value_counts())\n",
    "print(df_all['Functional'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Functional'] = df_all['Functional'].fillna(df_all['Functional'].mode()[0])\n",
    "#Confirm that the replacement occured succesfully.\n",
    "print(df_all['Functional'].value_counts())\n",
    "print(df_all['Functional'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Functional', y = 'SalePrice', data = df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exterior1st and Exterior2nd\n",
    "- Exterior1st: Exterior covering on house\n",
    "- Exteriors2nd: Exterior covering on house (if more than one material)\n",
    "- Categorical variable with 17 categories\n",
    "- Exterior1st, only ONE missing value\n",
    "- Ezterior2nd, only ONE missing value\n",
    "- Same argument as before, using MODE for replacement!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['Exterior1st'].value_counts())\n",
    "print(df_all['Exterior1st'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mode replacement\n",
    "df_all['Exterior1st'] = df_all['Exterior1st'].fillna(df_all['Exterior1st'].mode()[0])\n",
    "df_all['Exterior2nd'] = df_all['Exterior2nd'].fillna(df_all['Exterior2nd'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['Exterior2nd'].value_counts())\n",
    "print(df_all['Exterior2nd'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PUTTING THE LAST 5 LEVELS INTO ONE CALLED \"OTHER\" (reason is to bring down the number of dummy columns we create when do dummy encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.Exterior2nd.replace(\"Stone\", \"Other\", inplace=True)\n",
    "df_all.Exterior2nd.replace(\"AsphShn\", \"Other\", inplace=True)\n",
    "df_all.Exterior2nd.replace(\"CBlock\", \"Other\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kitchen Quality\n",
    "- Categorical with 5 categories\n",
    "- Only one missing value\n",
    "- Mode replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['KitchenQual'].value_counts())\n",
    "print(df_all['KitchenQual'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['KitchenQual'] = df_all['KitchenQual'].fillna(df_all['KitchenQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SaleType\n",
    "- Categorical with 10 categories\n",
    "- Only one missing value\n",
    "- Mode replacement again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['SaleType'].value_counts())\n",
    "print(df_all['SaleType'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'SaleType', y = 'SalePrice', data = df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We consider this as a paramount variable, so we will not aggregate or any other modifications..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mode Replacement\n",
    "df_all['SaleType'] = df_all['SaleType'].fillna(df_all['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrical\n",
    "- Categorical with 5 categories\n",
    "- Only one missing value\n",
    "- Mode replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_all['Electrical'].value_counts())\n",
    "print(df_all['Electrical'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Electrical'] = df_all['Electrical'].fillna(df_all['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSSubClass, MoSold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df_all.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "                                       150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df_all, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMERIC VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation -  Examining Correlation between predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.0, 10.0)\n",
    "corrmat = df_all.corr()\n",
    "top_corr_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.5]\n",
    "g = sns.heatmap(df_all[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliars!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GrLivArea\n",
    "- Observe a few outliers\n",
    "- Remove observations with a GrLivArea above 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'GrLivArea', y = 'SalePrice', data = df_train)\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping GrLivArea > 4000 & SalePrice < 12.5 (TrainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(df_all['GrLivArea']>4000) & (df_all['SalePrice']< 12.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all1 = df_all.drop(['523', '1298'])\n",
    "df_all = df_all[df_all.Id != 524]\n",
    "df_all = df_all[df_all.Id != 1299]\n",
    "#Confirming that we removed the two observations\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set is untouced!\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confirming that the observations was dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'GrLivArea', y = 'SalePrice', data = df_all)\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMATION OF SKEWED VARIABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform of the skewed numerical features to lessen impact of outliers\n",
    "# Inspired by Alexandru Papiu's script : https://www.kaggle.com/apapiu/house-prices-advanced-regression-techniques/regularized-linear-models\n",
    "# As a general rule of thumb, a skewness with an absolute value > 0.5 is considered at least moderately skewed\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "numerical_features = ['1stFlrSF',\n",
    "                      \"2ndFlrSF\",\n",
    "                      \"GrLivArea\",\n",
    "                      \"LotArea\",\n",
    "                      \"OpenPorchSF\",\n",
    "                      \"WoodDeckSF\"]\n",
    "\n",
    "train_num = df_all[numerical_features]\n",
    "\n",
    "skewness = train_num.apply(lambda x: skew(x) )\n",
    "skewness = skewness[abs(skewness) > 0.2]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "print(skewness)\n",
    "\n",
    "df_all[numerical_features] = np.log(df_all[numerical_features] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_all[numerical_features].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1: Total square feet\n",
    "df_all['TotLivArea'] = df_all.GrLivArea + df_all.TotalBsmtSF\n",
    "\n",
    "# 2: # Total number of bathrooms\n",
    "df_all['TotalBath'] = df_all['BsmtFullBath'] + (0.5 * df_all['BsmtHalfBath']) + df_all['FullBath'] + (0.5 * df_all['HalfBath'])\n",
    "\n",
    "# 3: BsmtUnFinRatio\n",
    "df_all['BsmtUnFinRatio'] = df_all.BsmtUnfSF / df_all.TotalBsmtSF \n",
    "df_all['BsmtUnFinRatio'] = df_all['BsmtUnFinRatio'].fillna(0)\n",
    "\n",
    "# 4: AreaPerCar\n",
    "df_all['AreaPerCar'] = df_all.GarageArea / df_all.GarageCars \n",
    "df_all['AreaPerCar'] = df_all['AreaPerCar'].fillna(0)\n",
    "\n",
    "\n",
    "# 5: AvgRoomSize \n",
    "df_all['AvgRoomSize'] = df_all.GrLivArea / df_all.TotRmsAbvGrd\n",
    "\n",
    "# SHOULD WE KEEP INTERACTION TERMS, I.E. NOT EXLUDE THEM?\n",
    "# 6: Condition should be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['OverallCond'] = df_all.OverallCond.replace({\n",
    "   1: 1, 2: 1, 3:1 , 4:1, 5:2, 6:3, 7:3, 8:3, 9:3, 10:3})\n",
    "df_all[\"OverallGrade\"] = df_all[\"OverallQual\"] * df_all[\"OverallCond\"]\n",
    "df_all['GarageScore'] = df_all.GarageCond * df_all.GarageQual * df_all.GarageArea\n",
    "df_all['FireScore'] = df_all.Fireplaces * df_all.FireplaceQu\n",
    "df_all[\"Overallscore\"] = df_all[\"OverallGrade\"]  * df_all['GrLivArea']\n",
    "df_all[\"ExterGrade\"] = df_all[\"ExterQual\"] * df_all[\"ExterCond\"]\n",
    "df_all[\"KitchenScore\"] = df_all[\"KitchenAbvGr\"] * df_all[\"KitchenQual\"]\n",
    "df_all[\"TotalBath\"] = df_all[\"BsmtFullBath\"] + (0.5 * df_all[\"BsmtHalfBath\"]) + \\\n",
    "df_all[\"FullBath\"] + (0.5 * df_all[\"HalfBath\"])\n",
    "df_all[\"AllSF\"] = df_all[\"GrLivArea\"] + df_all[\"TotalBsmtSF\"]\n",
    "df_all[\"AllPorchSF\"] = df_all[\"OpenPorchSF\"] + df_all[\"EnclosedPorch\"] + \\\n",
    "df_all[\"3SsnPorch\"] + df_all[\"ScreenPorch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Splitning the dataset back into training and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the data back into training and validate<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean_test=dummy_df[dummy_df.SalePrice.isnull()]\n",
    "df_clean_train=dummy_df[dummy_df.SalePrice.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure you have 1459 observations\n",
    "df_clean_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "df_clean_train.to_csv('cleaned_train_dummy_new_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "df_clean_test.to_csv('cleaned_test_dummy_new_feat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without dummifying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean_test=df_all[df_all.SalePrice.isnull()]\n",
    "df_clean_train=df_all[df_all.SalePrice.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the training and test set and excel.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean_test.to_csv('cleaned_test.csv')\n",
    "df_clean_train.to_csv('cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

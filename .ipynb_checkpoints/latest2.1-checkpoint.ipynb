{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/Users/Kenneth S. Hansen/Dropbox/NYC Data Science/Projects/Kaggle/test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response variable - SalePrice\n",
    "- Rigth / positive skewness\n",
    "- The response variable is NOT normal distributed, which means that we're violating our assumption in respect no normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c57c119c439c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#Histogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(df_train['SalePrice'].describe())\n",
    "#Histogram\n",
    "import seaborn as sns\n",
    "print(sns.distplot(df_train['SalePrice']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking how much SalePrice deviate from a normal distribution\n",
    "- Since it's very likely that I'm going to perform regressions (linear models), my depedent variables need to be \"somewhat\" normal distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = stats.probplot(df_train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Response Variable - SalePrice\n",
    "- Log Transform SalePrice\n",
    "- Reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train['SalePrice'] = np.log(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the transformed response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(df_train['SalePrice'], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "- Merging train and validate\n",
    "- Impute missing values (Handling missing data)\n",
    "- Categorical versus Numeric\n",
    "\n",
    "- df.all.describe(): shows a summary of the numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obs remember to exclude response variable, SalePrice\n",
    "frames = [df_train, df_test]\n",
    "df_all = pd.concat(frames)\n",
    "\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values - Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=0, summing each row for each column\n",
    "#isnull = return an boolean depending on missing or not\n",
    "\n",
    "#Calculat the ratio of missing values\n",
    "missing = (df_all.isnull().sum(axis=0) / len(df_all)*100).sort_values(ascending=False)\n",
    "\n",
    "#Dropping all \n",
    "missing = missing.drop(missing[missing==0].index)\n",
    "\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :missing})\n",
    "missing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated missing value table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#axis=0, summing each row for each column\n",
    "#isnull = return an boolean depending on missing or not\n",
    "\n",
    "#Calculat the ratio of missing values\n",
    "missing1 = (df_all.isnull().sum(axis=0) / len(df_all)*100).sort_values(ascending=False)\n",
    "\n",
    "#Dropping all \n",
    "missing1 = missing1.drop(missing1[missing1==0].index)\n",
    "\n",
    "missing_data_updated = pd.DataFrame({'Missing Ratio' :missing1})\n",
    "missing_data_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(15, 12))\n",
    "plt.xticks(rotation='90')\n",
    "sns.barplot(x=missing.index, y=missing)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Percent of missing values', fontsize=15)\n",
    "plt.title('Percent missing data by feature', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PoolQC, MiscFeature, Alley, Fence, FireplaceQu, 3SsnPorch binary\n",
    "- I perceive these features as being \"somewhat\" important, and these can indeed help explain the variation in my predictor SalePrice. The risk of converting these four variables into 1 and 0 is that I lose potential infromation in the levels.\n",
    "- Consider to go back and keep the levels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NA with None\n",
    "List_ = ['PoolQC', 'MiscFeature', 'Alley', 'Fence']\n",
    "df_all[List_] = df_all[List_].fillna('None')\n",
    "\n",
    "#Function to convert none = 0, and all other categories = 1\n",
    "def replace(x):\n",
    "    if x == 'None':\n",
    "        return 0\n",
    "    if x != 'None':\n",
    "        return 1\n",
    "   \n",
    " \n",
    "df_all['PoolQC'] = df_all['PoolQC'].apply(replace)\n",
    "df_all['MiscFeature'] = df_all['MiscFeature'].apply(replace)\n",
    "df_all['Alley'] = df_all['Alley'].apply(replace)\n",
    "df_all['Fence'] = df_all['Fence'].apply(replace)\n",
    "df_all['3SsnPorch'] = df_all['3SsnPorch'].apply(replace)\n",
    "\n",
    "\n",
    "print(df_all['PoolQC'].value_counts())\n",
    "print(df_all['Alley'].value_counts())\n",
    "print(df_all['Fence'].value_counts())\n",
    "print(df_all['MiscFeature'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CentralAir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.Series(df_all['CentralAir'].replace('Y', 1).replace('[^Y]', 0, regex=True))\n",
    "df_all['CentralAir'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['CentralAir'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3SsnPorch, LowQualFinSF \n",
    "- Convert into binary. Either the property has a house or it hasn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_ = ['3SsnPorch', 'LowQualFinSF']\n",
    "def replace1(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    if x != 0:\n",
    "        return 1\n",
    "\n",
    "df_all['3SsnPorch'] = df_all['3SsnPorch'].apply(replace1)\n",
    "df_all['LowQualFinSF'] = df_all['LowQualFinSF'].apply(replace1)\n",
    "print(df_all['3SsnPorch'].value_counts())\n",
    "print(df_all['LowQualFinSF'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FireplaceQC\n",
    "- Seems like fireplaces with an Excellent Quality tend to have higher median\n",
    "- Due to that, I want to keep my rank of the variable when converting to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['FireplaceQu'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['FireplaceQu'] = df_all['FireplaceQu'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thus, I might need to reconsider the way I handle the variable FireplaceQC. It could seems like excellent conditions of fireplaces\n",
    "#have a higher price.\n",
    "sns.boxplot(x = 'FireplaceQu', y = 'SalePrice', data = df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERT FIREPLACEQU SO IT KEEPS THE ORDER (0-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff_dict = {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n",
    "df_all[\"FireplaceQu\"] = df_all[\"FireplaceQu\"].map(ff_dict).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LotFrontage\n",
    "- LotFrontage is skweded, which means that we need to transform the variable. Here, there is a lot of various options. In this case, I take the median due the fact that we have extremes values. Taking the median makes the distribution less sensitive to these extremes values compared with taking the mean for instance.\n",
    "- Number of missing values: 486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['LotFrontage'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing missing values - LotFrontage\n",
    "- Sqrt of area as imputing, we assume that the lot is \"close\" to be sqaure shaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all.LotFrontage.isnull(), 'LotFrontage'] = np.sqrt(df_all.loc[df_all.LotFrontage.isnull()].LotArea)\n",
    "print(df_all['LotFrontage'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['LotFrontage'].describe())\n",
    "#Histogram\n",
    "import seaborn as sns\n",
    "sns.distplot(df_all['LotFrontage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is LotFrontage Versus SalePrice looking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'LotFrontage', y = 'SalePrice', data = df_train)\n",
    "plt.xlabel('LotFrontage')\n",
    "plt.ylabel('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garage Quality, Garage Type, Garage Finish, Garage Cond\n",
    "- Only five procent missing, and I consider to drop since GarageCars and GarageArea probably are better indicators\n",
    "- Therefore, I replace NA with None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Garage = ['GarageType', 'GarageFinish', 'GarageCond', 'GarageQual']\n",
    "df_all[List_Garage].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'GarageType', y = 'SalePrice', data = df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rplace missing values with None for Garage Quality, Garage Type, Garage Finish & Garage Condition\n",
    "df_all[List_Garage] = df_all[List_Garage].fillna('None')\n",
    "\n",
    "#confirm that 159 missing values were substitued with None\n",
    "df_all[List_Garage].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## dubble checking, what NA was replace with None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['GarageQual'] = df_all['GarageQual'].fillna('None')\n",
    "#confirm that 159 missing values were substitued with None\n",
    "df_all['GarageQual'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GarageYrBlt, Garage Area, Garage Cars\n",
    "- Replace missing with 0.\n",
    "- Seems like it is the same observations that are missing\n",
    "- GarageQuality and GarageYrBlt, this is probably due to the fact that the variable GarageCars = 0 means no cars in such garage, and therefore GarageYrBlt and GarageQuality is not represented!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Garage1 = ['GarageYrBlt', 'GarageArea', 'GarageCars']\n",
    "df_all[List_Garage1].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[List_Garage1] = df_all[List_Garage1].fillna(0)\n",
    "#confirm that NA was replaced with zero\n",
    "df_all[List_Garage1].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new variable GarageMissing, indicating that the property do NOT have a house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.Series(df_all['GarageQual'].replace('None', 1).replace('[^None]', 0, regex=True))\n",
    "df_all['GarageMissing'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath, BsmtHalfBath\n",
    "- All numeric values \n",
    "- Missing values means no basement\n",
    "- replace with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Bsmt_numeric = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "df_all[List_Bsmt_numeric].isnull().sum()\n",
    "#Observe that we only have few missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NA with zero\n",
    "df_all[List_Bsmt_numeric] = df_all[List_Bsmt_numeric].fillna(0)\n",
    "#confirm\n",
    "df_all[List_Bsmt_numeric].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2\n",
    "- Categorical variables\n",
    "- NA means that there is NO basement\n",
    "- Therefore replace NA with None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of missing values for each category\n",
    "List_Bsmt_categorical = ['BsmtQual', 'BsmtCond', 'BsmtExposure','BsmtFinType1', 'BsmtFinType2']\n",
    "df_all[List_Bsmt_categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing missing values\n",
    "df_all[List_Bsmt_categorical] = df_all[List_Bsmt_categorical].fillna('None')\n",
    "#Confrim that NA was replaced\n",
    "df_all[List_Bsmt_categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new variable BasementMissing, indicating that the property do NOT have an Basement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pd.Series(df_all['BsmtQual'].replace('None', 1).replace('[^None]', 0, regex=True))\n",
    "df_all['BasementMissing'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['BasementMissing'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MasVnrArea\n",
    "- Numeric variable\n",
    "- 0 indicate no sqaure meters of \"murværk\". Since MasVnrType Na means that the house has no \"murværk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of missing\n",
    "df_all['MasVnrArea'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MasVnrArea'] = df_all['MasVnrArea'].fillna(0)\n",
    "#confirm that Na was replaced with 0\n",
    "df_all['MasVnrArea'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MasVnrType\n",
    "- Categorical variable where NA means no \"murværk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MasVnrType'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MasVnrType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MasVnrType'] = df_all['MasVnrType'].fillna(\"None\") \n",
    "#confirm that Na was replaced with 0\n",
    "df_all['MasVnrType'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSZoning\n",
    "- Only four missing observations.\n",
    "- Observe that RL is significantly more represented that the 3 other MSZonings\n",
    "- mode should be appropriate in this case. Mode replaces missing with the value that is represented most\n",
    "- Recall that 0 is rowwise, while 1 is column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_all['MSZoning'].value_counts()\n",
    "(X)/(X).sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['MSZoning'].value_counts())\n",
    "print(df_all['MSZoning'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MSZoning'] = df_all['MSZoning'].fillna(df_all['MSZoning'].mode()[0])\n",
    "#Confirm that the replacement occured succesfully.\n",
    "print(df_all['MSZoning'].value_counts())\n",
    "print(df_all['MSZoning'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional\n",
    "- Categorical variable with 8 cateogories\n",
    "- describtion: : Home functionality (Assume typical unless deductions are warranted)\n",
    "- Taking the same approach as for MSzoning, type is clearly most represented!\n",
    "- Mode replacement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['Functional'].value_counts())\n",
    "print(df_all['Functional'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Functional'] = df_all['Functional'].fillna(df_all['Functional'].mode()[0])\n",
    "#Confirm that the replacement occured succesfully.\n",
    "print(df_all['Functional'].value_counts())\n",
    "print(df_all['Functional'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Functional', y = 'SalePrice', data = df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "- Categorical varible with four categories\n",
    "- Type of utilities available\n",
    "- Only 2 missing values\n",
    "- Taking the same approach as for MSzoning, type is clearly most represented!\n",
    "- Mode replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['Utilities'].value_counts())\n",
    "print(df_all['Utilities'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Utilities'] = df_all['Utilities'].fillna(df_all['Utilities'].mode()[0])\n",
    "#Confirm that the replacement occured succesfully.\n",
    "print(df_all['Utilities'].value_counts())\n",
    "print(df_all['Utilities'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exterior1st and Exterior2nd\n",
    "- Exterior1st: Exterior covering on house\n",
    "- Exteriors2nd: Exterior covering on house (if more than one material)\n",
    "- Categorical variable with 17 categories\n",
    "- Exterior1st, only ONE missing value\n",
    "- Ezterior2nd, only ONE missing value\n",
    "- Same argument as before, using MODE for replacement!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['Exterior1st'].value_counts())\n",
    "print(df_all['Exterior1st'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mode replacement\n",
    "df_all['Exterior1st'] = df_all['Exterior1st'].fillna(df_all['Exterior1st'].mode()[0])\n",
    "df_all['Exterior2nd'] = df_all['Exterior2nd'].fillna(df_all['Exterior2nd'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['Exterior2nd'].value_counts())\n",
    "print(df_all['Exterior2nd'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PUTTING THE LAST 5 LEVELS INTO ONE CALLED \"OTHER\" (reason is to bring down the number of dummy columns we create when do dummy encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all.Exterior2nd.replace(\"Stone\", \"Other\", inplace=True)\n",
    "df_all.Exterior2nd.replace(\"AsphShn\", \"Other\", inplace=True)\n",
    "df_all.Exterior2nd.replace(\"CBlock\", \"Other\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kitchen Quality\n",
    "- Categorical with 5 categories\n",
    "- Only one missing value\n",
    "- Mode replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['KitchenQual'].value_counts())\n",
    "print(df_all['KitchenQual'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['KitchenQual'] = df_all['KitchenQual'].fillna(df_all['KitchenQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SaleType\n",
    "- Categorical with 10 categories\n",
    "- Only one missing value\n",
    "- Mode replacement again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all['SaleType'].value_counts())\n",
    "print(df_all['SaleType'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'SaleType', y = 'SalePrice', data = df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We consider this as a paramount variable, so we will not aggregate or any other modifications..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mode Replacement\n",
    "df_all['SaleType'] = df_all['SaleType'].fillna(df_all['SaleType'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrical\n",
    "- Categorical with 5 categories\n",
    "- Only one missing value\n",
    "- Mode replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_all['Electrical'].value_counts())\n",
    "print(df_all['Electrical'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['Electrical'] = df_all['Electrical'].fillna(df_all['Electrical'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATUS: NONE of the variables contain MISSING VALUES now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEXT:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why? Should we convert ordinal variables to numeric. The boxplots below examplies that it might be a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'GarageQual', y = 'SalePrice', data = df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(5.0, 5.0)\n",
    "sns.boxplot(x = 'OverallQual', y = 'SalePrice', data = df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### NEXT: Convert all ORDINAL CATEGORICAL VARIABLES to NUMERIC\n",
    "#### Scale: \n",
    "- None: 0, Po:1, Fa: 2, TA: 3, Gd: 4, Ex: 5\n",
    "#### Variables:\n",
    "    - ExterQual\n",
    "    - ExterCond\n",
    "    - BsmtCond\n",
    "    - HeatingQC\n",
    "    - KitchenQual\n",
    "    - FirePlaceQu\n",
    "    - GarageQual\n",
    "    - GarageCond\n",
    "    - PoolQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qual_dict = {\"None\": 0, \"Po\": 1, \"Fa\": 2, \"TA\": 3, \"Gd\": 4, \"Ex\": 5}\n",
    "df_all[\"ExterCond\"] = df_all[\"ExterCond\"].map(qual_dict).astype(int)\n",
    "df_all[\"ExterQual\"] = df_all[\"ExterQual\"].map(qual_dict).astype(int)\n",
    "df_all[\"BsmtQual\"] = df_all[\"BsmtQual\"].map(qual_dict).astype(int)\n",
    "df_all[\"BsmtCond\"] = df_all[\"BsmtCond\"].map(qual_dict).astype(int)\n",
    "df_all[\"HeatingQC\"] = df_all[\"HeatingQC\"].map(qual_dict).astype(int)\n",
    "df_all[\"KitchenQual\"] = df_all[\"KitchenQual\"].map(qual_dict).astype(int)\n",
    "df_all[\"GarageQual\"] = df_all[\"GarageQual\"].map(qual_dict).astype(int)\n",
    "df_all[\"GarageCond\"] = df_all[\"GarageCond\"].map(qual_dict).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GarageFinish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qual_dict_garage = {\"None\": 0, \"Unf\": 1, \"RFn\": 2, \"Fin\": 3}\n",
    "df_all[\"GarageFinish\"] = df_all[\"GarageFinish\"].map(qual_dict_garage).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtFinType1, BsmtFinType2\n",
    "#### Scale:  \n",
    "- None: 0, Unf: 1, LwQ: 2, Rec: 3, BLQ: 4, ALQ: 5, GLQ: 6\n",
    "    #### Variables:\n",
    "    - BsmtFinType1\n",
    "    - BsmtFinType2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bsmt_fin_dict = {\"None\": 0, \"Unf\": 1, \"LwQ\": 2, \"Rec\": 3, \"BLQ\": 4, \"ALQ\": 5, \"GLQ\": 6}\n",
    "df_all[\"BsmtFinType1\"] = df_all[\"BsmtFinType1\"].map(bsmt_fin_dict).astype(int)\n",
    "df_all[\"BsmtFinType2\"] = df_all[\"BsmtFinType2\"].map(bsmt_fin_dict).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BsmtExposure\n",
    "#### Scale:  \n",
    "- \"None\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4\n",
    "    #### Variables:\n",
    "    - BsmtExposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all[\"BsmtExposure\"] = df_all[\"BsmtExposure\"].map({\"None\": 0, \"No\": 1, \"Mn\": 2, \"Av\": 3, \"Gd\": 4}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all[\"Functional\"] = df_all[\"Functional\"].map({None: 0, \"Sal\": 1, \"Sev\": 2, \"Maj2\": 3, \"Maj1\": 4, \"Mod\": 5, \"Min2\": 6, \"Min1\": 7, \"Typ\": 8}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### LabelCountEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabelCountEncoder(object):\n",
    "    def __init__(self):\n",
    "        self.count_dict = {}\n",
    "    \n",
    "    def fit(self, column):\n",
    "        # This gives you a dictionary with level as the key and counts as the value\n",
    "        count = column.value_counts().to_dict()\n",
    "        # We want to rank the key by its value and use the rank as the new value\n",
    "        self.count_dict = {key[0]: rank+1 for rank, key in enumerate(sorted(count.items(), key=lambda x: x[1]))}\n",
    "    \n",
    "    def transform(self, column):\n",
    "        # If a category only appears in the test set, we will assign the value to zero.\n",
    "        missing = 0\n",
    "        return column.apply(lambda x : self.count_dict.get(x, missing))\n",
    "    \n",
    "    def fit_transform(self, column):\n",
    "        self.fit(column)\n",
    "        return self.transform(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1_ = ['MSZoning', 'Neighborhood', 'LotConfig', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', \n",
    "       'Exterior1st', 'Exterior2nd', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'Foundation',\n",
    "      'Heating', 'Electrical', 'GarageType', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
    "\n",
    "for c in df_all[list1_]:\n",
    "    lce = LabelCountEncoder()\n",
    "    df_all[c] = lce.fit_transform(df_all[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSZoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation -  Examining Correlation between predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.0, 10.0)\n",
    "corrmat = df_all.corr()\n",
    "top_corr_features = corrmat.index[abs(corrmat[\"SalePrice\"])>0.5]\n",
    "g = sns.heatmap(df_all[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1: Total square feet\n",
    "df_all['TotLivArea'] = df_all.GrLivArea + df_all.TotalBsmtSF\n",
    "\n",
    "# 2: # Total number of bathrooms\n",
    "df_all['TotalBath'] = df_all['BsmtFullBath'] + (0.5 * df_all['BsmtHalfBath']) + df_all['FullBath'] + (0.5 * df_all['HalfBath'])\n",
    "\n",
    "# 3: BsmtUnFinRatio\n",
    "df_all['BsmtUnFinRatio'] = df_all.BsmtUnfSF / df_all.TotalBsmtSF \n",
    "df_all['BsmtUnFinRatio'] = df_all['BsmtUnFinRatio'].fillna(0)\n",
    "\n",
    "# 4: AreaPerCar\n",
    "df_all['AreaPerCar'] = df_all.GarageArea / df_all.GarageCars \n",
    "df_all['AreaPerCar'] = df_all['AreaPerCar'].fillna(0)\n",
    "\n",
    "\n",
    "# 5: AvgRoomSize \n",
    "df_all['AvgRoomSize'] = df_all.GrLivArea / df_all.TotRmsAbvGrd\n",
    "\n",
    "# SHOULD WE KEEP INTERACTION TERMS, I.E. NOT EXLUDE THEM?\n",
    "# 6: Condition should be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.AreaPerCar.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.GarageCars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.GarageArea.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMATION OF SKEWED VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform of the skewed numerical features to lessen impact of outliers\n",
    "# Inspired by Alexandru Papiu's script : https://www.kaggle.com/apapiu/house-prices-advanced-regression-techniques/regularized-linear-models\n",
    "# As a general rule of thumb, a skewness with an absolute value > 0.5 is considered at least moderately skewed\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "numerical_features = ['1stFlrSF',\n",
    "                      \"2ndFlrSF\",\n",
    "                      \"GrLivArea\",\n",
    "                      \"LotArea\",\n",
    "                      \"OpenPorchSF\",\n",
    "                      \"WoodDeckSF\"]\n",
    "\n",
    "train_num = df_all[numerical_features]\n",
    "\n",
    "skewness = train_num.apply(lambda x: skew(x) )\n",
    "skewness = skewness[abs(skewness) > 0.2]\n",
    "print(str(skewness.shape[0]) + \" skewed numerical features to log transform\")\n",
    "skewed_features = skewness.index\n",
    "print(skewness)\n",
    "\n",
    "df_all[numerical_features] = np.log(df_all[numerical_features] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[numerical_features].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliars!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GrLivArea\n",
    "- Observe a few outliers\n",
    "- Remove observations with a GrLivArea above 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'GrLivArea', y = 'SalePrice', data = df_train)\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('SalePrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Dropping GrLivArea > 4000 & SalePrice < 12.5 (TrainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[(df_all['GrLivArea']>4000) & (df_all['SalePrice']< 12.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all1 = df_all.drop(['523', '1298'])\n",
    "df_all = df_all[df_all.Id != 524]\n",
    "df_all = df_all[df_all.Id != 1299]\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##df_all.drop(df_all[df_all[\"GrLivArea\"] > 4000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confirming that the observations was dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = 'GrLivArea', y = 'SalePrice', data = df_all)\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['PavedDrive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the entire dataframe\n",
    "pd.set_option('display.max_columns', 80)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# DROP THE FOLLOWING VARIABLES:\n",
    "- UTILITIES: Because it's a constant\n",
    "- POOLAREA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.drop(['Utilities', 'PoolArea']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Splitning the dataset back into training and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummyfi variables\n",
    "- IMPORTANT drop the first variable in the dummyfied variable. Dropping the first column avoiding collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(df_all, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "dummy_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting the data back into training and validate<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean_test=dummy_df[dummy_df.SalePrice.isnull()]\n",
    "df_clean_train=dummy_df[dummy_df.SalePrice.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure you have 1459 observations\n",
    "df_clean_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train\n",
    "df_clean_train.to_csv('cleaned_train_dummy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "df_clean_test.to_csv('cleaned_test_dummy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without dummifying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean_test=df_all[df_all.SalePrice.isnull()]\n",
    "df_clean_train=df_all[df_all.SalePrice.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the training and test set and excel.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean_test.to_csv('cleaned_test.csv')\n",
    "df_clean_train.to_csv('cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
